{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0f04fb",
   "metadata": {},
   "source": [
    "# Section 5\n",
    "\n",
    "This file runs the per-fold ranking using feature importance for our top two performing classifiers from Section 4. In the paper, these classifiers were the logistic regression and LGBM. The procedure is model-specific. Here, we don't have weighted (w) and unweighted (u) versions of the data as in the original pipeline; it is, however, the same procedure for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd86d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# local modules\n",
    "from _utils import *\n",
    "\n",
    "from functools import reduce\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3fa5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings  \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('font', size=16)\n",
    "plt.rc('legend', fontsize=16)\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('axes', linewidth=2)\n",
    "plt.rc('axes', edgecolor='k')\n",
    "plt.rc('xtick.major', width=2)\n",
    "plt.rc('xtick.major', size=10)\n",
    "plt.rc('ytick.major', width=2)\n",
    "plt.rc('ytick.major', size=10)\n",
    "plt.rc('pdf', fonttype=42)\n",
    "plt.rc('ps', fonttype=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a12fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "os.chdir(\"..\")\n",
    "wd = os.getcwd()\n",
    "# data folder\n",
    "data_path = wd + '/' + 'data' + '/'\n",
    "# results folder\n",
    "resu_path = wd + '/' + 'results' + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba38a2e",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbce2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of datasets\n",
    "ls_clf_type     = ['LGBM2', 'LR']\n",
    "ls_dataset_type = ['bible_belt']\n",
    "# ls_dataset_type = ['item', 'theme']  # See paper for details: We don't have this type of data setting\n",
    "\n",
    "# store all results here\n",
    "all_results = {}\n",
    "\n",
    "# top-k\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bcce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> run UNWEIGHTED\n"
     ]
    }
   ],
   "source": [
    "# use 'w' for weighted or 'u' for unweighted - the latter used as default\n",
    "experiment_type = 'u' \n",
    "\n",
    "if experiment_type == 'w':\n",
    "    filename = 'experiment_results_w.pkl'\n",
    "    print('---> run WEIGHTED')\n",
    "else:\n",
    "    filename = 'experiment_results.pkl'\n",
    "    print('---> run UNWEIGHTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64199b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for exisiting results\n",
    "all_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6934ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the results from Section 4 - hence, load from results folder\n",
    "with open(resu_path + filename, 'rb') as f: \n",
    "    [target, \n",
    "     categorical_columns, \n",
    "     cat_feats, con_feats, ord_feats, all_feats, \n",
    "     state_encoder, sex_encoder, race_encoder, \n",
    "     weight_column, \n",
    "     dataset, \n",
    "     experiment_results, final_results] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc560e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>Y</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5510.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P  Y  STATE\n",
       "0  32.0  2.0  19.0  5.0  5510.0    2.0   7.0  40.0    0      6  1      0\n",
       "1  61.0  4.0  16.0  1.0  4220.0    2.0   1.0  40.0    1      4  0      0\n",
       "2  65.0  2.0  21.0  1.0  6200.0    2.0   0.0  35.0    1      3  1      0\n",
       "3  38.0  1.0  17.0  4.0   310.0   46.0   0.0  30.0    0      6  0      0\n",
       "4  50.0  1.0  21.0  1.0  3255.0  328.0   0.0  50.0    0      1  1      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449ef36",
   "metadata": {},
   "source": [
    "## Extract and rank feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2e1713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM2\n",
      "bible_belt\n",
      "(6, 9)\n",
      "(235893,)\n",
      "(235893, 11)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7789355153603348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789355153603348\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6437596878291109, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6437596878291109\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8577577792661564, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8577577792661564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40648792269514766, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40648792269514766\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7141653713024363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7141653713024363\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10020647866897148, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10020647866897148\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5194238019233199, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5194238019233199\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42165623504513017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42165623504513017\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9089757436394137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9089757436394137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6844317511858413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6844317511858413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7551290984043468, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7551290984043468\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6739354941526675, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6739354941526675\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9174432270540904, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9174432270540904\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5034380303298535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5034380303298535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8106775600700995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8106775600700995\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7149633063650149, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7149633063650149\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8650214129011375, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8650214129011375\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4077438359838218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4077438359838218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.96264223918917, subsample=1.0 will be ignored. Current value: bagging_fraction=0.96264223918917\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9083064687048718, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9083064687048718\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8619465806149611, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8619465806149611\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19603436619603887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19603436619603887\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8068846776736418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8068846776736418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3202664490245678, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3202664490245678\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "(506, 6)\n",
      "(506, 6)\n",
      "u_LGBM2_bible_belt\n",
      "LR\n",
      "bible_belt\n",
      "(6, 9)\n",
      "(235893,)\n",
      "(235893, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "(506, 6)\n",
      "(506, 6)\n",
      "u_LR_bible_belt\n",
      "DONE\n",
      "dict_keys(['u_LGBM2_bible_belt', 'u_LR_bible_belt'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf_type in ls_clf_type:\n",
    "    print(clf_type)\n",
    "    \n",
    "# ---------- ---------- ---------- ---------- ----------\n",
    "    \n",
    "    for dataset_type in ls_dataset_type:\n",
    "        print(dataset_type)\n",
    "        \n",
    "        # Get clf-dataset type specific experimental results\n",
    "        temp_experiment_results = experiment_results[(experiment_results['clf_name'] == clf_type) & (experiment_results['dataset'] == dataset_type)]\n",
    "        print(temp_experiment_results.shape)\n",
    "        \n",
    "        # define dataset\n",
    "        X = dataset.copy()\n",
    "        y = X[target]\n",
    "        X.drop(columns = [target], inplace = True)\n",
    "        print(y.shape)\n",
    "        print(X.shape)\n",
    "        \n",
    "#         # define dataset\n",
    "#         X = datasets[dataset_type].copy()\n",
    "#         y = X[target]\n",
    "#         X.drop(columns = [target], inplace = True)\n",
    "#         print(y.shape)\n",
    "#         print(X.shape)\n",
    "        \n",
    "# ---------- ---------- ---------- ---------- ----------\n",
    "        \n",
    "        # store internal results\n",
    "        temp_fold_results = []\n",
    "        temp_rank_results = []\n",
    "\n",
    "        fold = 0\n",
    "        \n",
    "        for ind, row in temp_experiment_results.iterrows():\n",
    "    \n",
    "            fold += 1\n",
    "    \n",
    "            # training set\n",
    "            train = row['train']\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "            sw_train = weight_column.iloc[train] if weight_column is not None else None\n",
    "            # test set\n",
    "            test = row['test']\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "            sw_test = weight_column.iloc[test] if weight_column is not None else None\n",
    "    \n",
    "            # build model\n",
    "            clf = build_model(row['clf_name'], categorical_columns, row['best_hyparams'])\n",
    "            # fit model\n",
    "            clf.fit(X_train, y_train, clf__sample_weight=sw_train)\n",
    "            # test model\n",
    "            y_scores = clf.predict_proba(X_test)[:,1] \n",
    "            ap = average_precision_score(y_test, y_scores, sample_weight=sw_test)\n",
    "            # should be the same!\n",
    "            #print(ap , row['ap_test'])\n",
    "    \n",
    "            coef_col_name = 'imp_f' + str(fold) # for LR imp is the coefs and for LGBM is the feat_importance\n",
    "            ranking = 'rank_f' + str(fold)\n",
    "\n",
    "            if clf_type == 'LR':        \n",
    "                # get imp\n",
    "                temp_betas_0 = pd.DataFrame(zip(clf['one hot'].get_feature_names(), \n",
    "                                                np.transpose(clf['clf'].coef_)), \n",
    "                                          columns=['features', coef_col_name])\n",
    "                # remove [] and round up\n",
    "                temp_betas_0[coef_col_name] = temp_betas_0[coef_col_name].map(lambda x: round(x[0], 3)) # only diff wrt LGBM\n",
    "\n",
    "                # store\n",
    "                temp_fold_results.append(temp_betas_0)\n",
    "                temp_betas = temp_betas_0.copy()\n",
    "                # clear\n",
    "                del temp_betas_0\n",
    "\n",
    "                # get ranking\n",
    "                temp_betas[coef_col_name] = temp_betas[coef_col_name].map(lambda x: abs(x)) # only diff wrt LGBM\n",
    "                temp_betas.sort_values(by=coef_col_name, ascending=False, inplace=True)\n",
    "                temp_betas[ranking] = temp_betas[coef_col_name].rank(method='dense', ascending=False).astype(int)\n",
    "                temp_betas.drop([coef_col_name], axis=1, inplace=True)\n",
    "\n",
    "                # store\n",
    "                temp_rank_results.append(temp_betas)\n",
    "\n",
    "            else: # only for LGBM2\n",
    "                # get imp\n",
    "                temp_betas_0 = pd.DataFrame(zip(clf['one hot'].get_feature_names(), \n",
    "                                                np.transpose(clf['clf'].feature_importances_)), \n",
    "                                            columns=['features', coef_col_name])\n",
    "\n",
    "                # store\n",
    "                temp_fold_results.append(temp_betas_0)\n",
    "                temp_betas = temp_betas_0.copy()\n",
    "                # clear\n",
    "                del temp_betas_0\n",
    "\n",
    "                # get ranking\n",
    "                temp_betas.sort_values(by=coef_col_name, ascending=False, inplace=True)\n",
    "                temp_betas[ranking] = temp_betas[coef_col_name].rank(method='dense', ascending=False).astype(int)\n",
    "                temp_betas.drop([coef_col_name], axis=1, inplace=True)\n",
    "\n",
    "                # store\n",
    "                temp_rank_results.append(temp_betas)\n",
    "\n",
    "            # clear\n",
    "            del temp_betas, coef_col_name\n",
    "\n",
    "        print(len(temp_fold_results))\n",
    "        print(len(temp_rank_results))\n",
    "        \n",
    "# ---------- ---------- ---------- ---------- ----------\n",
    "        \n",
    "        # get fold results\n",
    "        fold_results = reduce(lambda df1, df2: pd.merge(df1, df2, on='features'), temp_fold_results)\n",
    "        fold_results.set_index(['features'], drop=True, inplace=True)\n",
    "        \n",
    "        print(fold_results.shape)\n",
    "        fold_results_org = fold_results.copy()\n",
    "        \n",
    "        fold_results['imp_avg'] = fold_results.mean(axis=1)\n",
    "        fold_results['imp_std'] = fold_results.std(axis=1)\n",
    "        if clf_type == 'LR':\n",
    "            fold_results['abs_imp_avg'] = fold_results['imp_avg'].abs()\n",
    "            res1 = fold_results.sort_values(by=['abs_imp_avg'], \n",
    "                                            ascending=[False], axis=0)[['abs_imp_avg', 'imp_avg', 'imp_std']] #.head(top_k)\n",
    "        else:\n",
    "            res1 = fold_results.sort_values(by=['imp_avg'], \n",
    "                                            ascending=[False], axis=0)[['imp_avg', 'imp_std']] #.head(top_k)\n",
    "        \n",
    "        # get rankings\n",
    "        rank_results = reduce(lambda df1, df2: pd.merge(df1, df2, on='features'), temp_rank_results)\n",
    "        rank_results.set_index(['features'], drop=True, inplace=True)\n",
    "        \n",
    "        print(rank_results.shape)\n",
    "        rank_results_org = rank_results.copy()\n",
    "        \n",
    "        rank_results['final_ranking_points'] = rank_results.sum(axis=1) #round(rank_results.sum(axis=1) / 100)\n",
    "        #^ so 100 would be the perfect score is it means the feat was ranked 1st over all 100 folds\n",
    "        rank_results.sort_values(by=['final_ranking_points'], \n",
    "                                 ascending=[True], axis=0, inplace=True)\n",
    "        rank_results['final_ranking'] = rank_results['final_ranking_points'].rank(method='first').astype(int)\n",
    "        res2 = rank_results[['final_ranking_points', 'final_ranking']] #.head(top_k)\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ----------\n",
    "        \n",
    "        # store results\n",
    "        run_type = experiment_type + '_' + clf_type + '_' + dataset_type\n",
    "\n",
    "        print(run_type)\n",
    "\n",
    "        all_results[run_type] = {}\n",
    "        all_results[run_type]['fold_results'] = fold_results_org\n",
    "        all_results[run_type]['rank_results'] = rank_results_org\n",
    "        all_results[run_type]['feat_desc'] = res1\n",
    "        all_results[run_type]['feat_rank'] = res2\n",
    "        all_results[run_type]['top_k'] = res2.index.to_list()[:k]\n",
    "\n",
    "        del run_type\n",
    "        del fold_results_org, rank_results_org, fold_results, rank_results, res1, res2\n",
    "\n",
    "# ---------- ---------- ---------- ---------- ----------\n",
    "\n",
    "print('DONE')\n",
    "\n",
    "print(all_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce383e6",
   "metadata": {},
   "source": [
    "## Prepare the rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861be793",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_type in all_results.keys():\n",
    "    \n",
    "    # Feature feat. imp. description\n",
    "    name1 = \"\\\\\"  + \"lar_\" + run_type + \"_\" + 'feat_desc'\n",
    "    all_results[run_type]['feat_desc'].to_csv(resu_path + name1 + '.csv')\n",
    "    \n",
    "    # Feature feat. imp. ranking\n",
    "    name2 = \"\\\\\" + \"lar_\" + run_type + \"_\" + 'feat_rank'\n",
    "    all_results[run_type]['feat_rank'].to_csv(resu_path + name2 + '.csv')\n",
    "    \n",
    "    del name1, name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f62056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGEP',\n",
       " 'WKHP',\n",
       " 'COW',\n",
       " 'POBP',\n",
       " 'SCHL',\n",
       " 'RELP',\n",
       " 'onehot__x0_0',\n",
       " 'onehot__x1_6',\n",
       " 'onehot__x4_3255.0',\n",
       " 'onehot__x2_2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results['u_LGBM2_bible_belt']['top_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "207dd88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WKHP',\n",
       " 'SCHL',\n",
       " 'onehot__x4_1106.0',\n",
       " 'AGEP',\n",
       " 'onehot__x4_4930.0',\n",
       " 'onehot__x4_1320.0',\n",
       " 'onehot__x4_300.0',\n",
       " 'onehot__x4_1350.0',\n",
       " 'onehot__x4_4030.0',\n",
       " 'onehot__x4_820.0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results['u_LR_bible_belt']['top_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7efdd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TABLE 1\n",
    "# df_res_items = pd.DataFrame()\n",
    "\n",
    "# for i in dict((k, all_results[k]) for k in res_items).keys():\n",
    "#     df_res_items[i] = all_results[i]['top_k']\n",
    "\n",
    "# df_res_items['Ranking'] = df_res_items.index + 1\n",
    "# df_res_items\n",
    "\n",
    "# # For Latex document\n",
    "# print(df_res_items.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "936d8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TABLE 2\n",
    "# df_res_themes = pd.DataFrame()\n",
    "\n",
    "# for i in dict((k, all_results[k]) for k in res_themes).keys():\n",
    "#     df_res_themes[i] = all_results[i]['top_k']\n",
    "\n",
    "# df_res_themes\n",
    "\n",
    "# # for latex output\n",
    "# print(df_res_themes.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c97a6e",
   "metadata": {},
   "source": [
    "## Critical difference test for LGBM classifier for top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67746c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a74415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7181b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a703fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661128d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
